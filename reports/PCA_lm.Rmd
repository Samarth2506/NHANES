---
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
rm(list = ls())
if(T){
  library(rnhanesdata)
  library(tidyverse)
  library(magrittr)
  library(data.table)
  library(randomForest)
  library(caret)
  library(keras)
  library(tensorflow)
}
```

## Logistic regression based on PC scores
```{r}
load(file = "analyticData.rda")
analyticData = analyticData %>% select(-permth_exm)
# NA: alive
# 1: deceased
analyticData$mortstat = ifelse(analyticData$mortstat %>% is.na,1,0)
# 1: alive, 0 : deceased

pca = prcomp(analyticData %>% select(-SEQN,-mortstat) %>% na.omit() ,
             center = T,
             scale. = T)

if(F){
  save(pca,file = 'pca.rda')
}
screeplot(pca)

pcscore = data.frame(SEQN = analyticData %>% na.omit %>% select(SEQN),
                       pca$x,
                       mortstat = analyticData %>% na.omit %>% select(mortstat))
if(F){
  save(pcscore,file = 'pcscore.rda')
}
# first 5 PCs
y = pcscore[,c(2:6,which(colnames(pcscore) == 'mortstat'))]
y$mortstat = as.factor(y$mortstat)
set.seed(100)
# trainIdx = sample(c(TRUE, FALSE), dim(y)[1], replace = TRUE, prob = c(.7, .3))
trainIdx = sample(dim(y)[1],0.7*dim(y)[1])
fit = glm(mortstat ~ ., family = "binomial", data = y, subset = trainIdx)
summary(fit)
```


```{r}
yPred =  (predict(fit, y[-trainIdx,], type = "response") > 0.5) * 1
ytest = y[-trainIdx, ]
ptab = table(ytest[,"mortstat"], yPred %>% factor(levels = levels(ytest[,"mortstat"] )))
# result
ptab
# acc
sum(diag(ptab)) / sum(ptab)
```

## BMI prediction based on raw data using lm

```{r}
load(file = 'analyticData.rda')
analyticData = analyticData %>% select(-mortstat,-permth_exm) %>%
  inner_join(Covariate_D %>% select(SEQN,BMI),by = "SEQN")

analyticData$'log(BMI+1)' = log(analyticData$BMI+1)


y = analyticData %>% select(-SEQN)


set.seed(100)
BMI = y$BMI 
y = y %>% select(-BMI)
trainIdx = sample(nrow(y),0.7*nrow(y))

fit = lm( y$`log(BMI+1)` ~  ., data = y, subset = trainIdx)
# summary(fit)
yPred = exp(predict(fit,y[-trainIdx,]))-1
result = cbind(yPred,yTrue = BMI[-trainIdx]) %>% na.omit() %>% as.data.frame()
modelmse = mean(summary(fit)$residuals^2)
# model MSE
modelmse

# MSE of yPred and yTrue
mean((result[,1]-result[,2])^2)

# visualization
library(ggplot2)
ggplot(data=result , aes(x = 1:dim(result)[1])) + 
  geom_line(aes(y = yPred),color = 'red') + 
  geom_line(aes(y = yTrue),color = 'blue')
```

## BMI prediction based on PC scores using lm
```{r}
load(file = 'pcscore.rda')

pcscore = pcscore %>% select(-mortstat) %>% 
  inner_join(Covariate_D %>% select(SEQN,BMI),by = "SEQN")

y = pcscore %>% select(-SEQN)



BMI = y$BMI 
y = y %>% select(-BMI) %>% mutate('log(BMI+1)' = log(BMI+1))
set.seed(100)
trainIdx = sample(nrow(y),0.7*nrow(y))

fit = lm( y$`log(BMI+1)` ~  ., data = y, subset = trainIdx)
# summary(fit)
yPred = exp(predict(fit,y[-trainIdx,]))-1
result = cbind(yPred,yTrue = BMI[-trainIdx]) %>% na.omit() %>% as.data.frame()
# modelmse = mean(summary(fit)$residuals^2)
# # model MSE
# modelmse

# MSE of yPred and yTrue
mean((result[,1]-result[,2])^2)

# visualization
library(ggplot2)
ggplot(data=result , aes(x = 1:dim(result)[1])) + 
  geom_line(aes(y = yPred),color = 'red') + 
  geom_line(aes(y = yTrue),color = 'blue') + 
  labs(title = "All PCs included")
```


```{r}

ysub = y[,c(1:200,which(colnames(y) == 'log(BMI+1)'))]
fit = lm( ysub$`log(BMI+1)` ~., data = ysub, subset = trainIdx)
# summary(fit)
yPred = exp(predict(fit,ysub[-trainIdx,]))-1
result = cbind(yPred,yTrue = BMI[-trainIdx]) %>% na.omit() %>% as.data.frame()
modelmse = mean(summary(fit)$residuals^2)
# model MSE
modelmse

# MSE of yPred and yTrue
mean((result[,1]-result[,2])^2)

# visualization
library(ggplot2)
ggplot(data=result , aes(x = 1:dim(result)[1])) + 
  geom_line(aes(y = yPred),color = 'red') + 
  geom_line(aes(y = yTrue),color = 'blue') + 
  labs(title  = "First 200 PCs included")
```


